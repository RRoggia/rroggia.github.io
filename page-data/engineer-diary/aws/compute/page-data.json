{
    "componentChunkName": "component---src-templates-folder-template-js",
    "path": "/engineer-diary/aws/compute",
    "result": {"pageContext":{"parentPath":"/engineer-diary/aws/compute","files":[{"fileAbsolutePath":"/home/runner/work/rroggia.github.io/rroggia.github.io/engineer-diary/AWS/compute/elastic-compute-cloud.md","html":"<p><a href=\"https://docs.aws.amazon.com/ec2/index.html\">Documentation</a></p>\n<h2>Overview</h2>\n<p>EC2 is one of the AWS compute offers. You can easily create a virtual infrastructure to run your workloads with EC2. EC2 is a AZ Resilient service.</p>\n<h2>Core Concepts</h2>\n<p>In EC2 you spin up <strong>instances</strong> (virtual computing environments) based on a <strong>instance type</strong>. The <strong>instance type</strong> is the hardware configuration that determines CPU, memory, storage, and networking capacity. The instance types can be categorized depending on the workload they best suit.</p>\n<ul>\n<li><strong>General Purpose</strong>: A balance of compute, memory, and networking resources, and can be used for a wide range of workloads</li>\n<li><strong>Compute Optimized</strong>: High-performance processors</li>\n<li><strong>Memory Optimized</strong>: Workloads that process large data sets in memory</li>\n<li><strong>Accelerated Computing</strong>: Uses hardware accelerators, or co-processors, to perform some functions, such as floating point number calculations, graphics processing, or data pattern matching, more efficiently than is possible in software running on CPUs</li>\n<li><strong>Storage Optimized</strong>: High, sequential read and write access to very large data sets on local storage</li>\n</ul>\n<p>Each category has <strong>families</strong>, a group of instance types within a family that have common workloads. A category can have several families each supporting a different workload.</p>\n<p>Each family contains the <strong>generations</strong> of a instance type. Each new generation improves the existing and has slightly variations on the instance type. </p>\n<p>An instance also has a <strong>size</strong> which vary accordingly with the family and generation. Some examples are <em>nano</em>, <em>medium</em> and <em>xlarge</em>.</p>\n<p>You read the instance type from left to right. For example the instance type <em>c5n.xlarge</em> reads as:</p>\n<ul>\n<li>Instance family: c - Compute Optimized</li>\n<li>Instance generation: 5</li>\n<li>Attribute: n - Network optimization</li>\n<li>Instance size: xlarge</li>\n</ul>\n<p>EC2 Instances are private services, they run within VPC's subnet. They are AZ resilient, if an AZ fails the whole subnet with the EC2 instances fail. EC2 instances run in a <strong>EC2 Host</strong>, which is are the racks with servers in AWS datacenter. Usually one EC2 Host is shared by several customers but the EC2 instances are isolated. However, it's possible to allocate <strong>Dedicated host</strong>.</p>\n<p>When you launch a EC2 machine you need to select a <strong>Amazon Machine Image, or AMI</strong>. AMI provides the information required to launch an instance. There are several AMI Types which are Quick Start, AWS Marketplace, My and Community. You can search for AMIs using the  <strong>AMI Catalog</strong>.</p>\n<p>An AMI is a region specific resource and it's composed by:</p>\n<ul>\n<li><strong>Root Volume Template</strong>: which is the drive that boots the OS.</li>\n<li><strong>Launch Permissions</strong>: Who is allowed to use the AMI to launch instances.</li>\n<li><strong>Block Device Mapping</strong>: Specifies the volumes to attach to the instance when it's launched.</li>\n</ul>\n<p>A AMI's Launch Permission can be <strong>Public</strong>, where all AWS accounts can access it. It can be <strong>Implicit</strong>, only the owner has access to launch EC2 instances. Or it can also be <strong>Explicit</strong>, where you can choose which AWS Accounts can access it. An AMI can be baked by using EBS or EC2 instance store.</p>\n<p>You can create an AMI from a running EC2 instance. When you create it, it creates a EBS Snapshot. AMIs cannot be changed once they are created. But, you can create a copy, and you can even change the region of the copy. If you are finished using the AMI you can deregister it.</p>\n<p>The EC2 Instance can assume the following states:</p>\n<ul>\n<li><strong>Pending</strong>: When launched or restarted. Moves to running</li>\n<li><strong>Running</strong>: Moves to Rebooting, Stopping or shutting-down.</li>\n<li><strong>Rebooting</strong>: Moves to Running.</li>\n<li><strong>Stopping</strong>: Moves to Stopped.</li>\n<li><strong>Stopped</strong>: Moves to pending.</li>\n<li><strong>Shutting-down</strong>: Moves to terminated.</li>\n<li><strong>Terminated</strong>: Ends life cycle.</li>\n</ul>\n<p>EC2 offers several <strong>Launch types</strong> that apply different charge rates. But, in general you are going to be charged for compute capacity per hour or per second, data transfer out to the internet and within the same region are also charged and additional Elastic IP addresses are also charged.You are only charged during the running or in the stopping state when it's preparing for hibernation. This is because EC2 needs to copy the memory to the EBS root volume.</p>\n<p><strong>On demand</strong> EC2 instances you pay per second of the compute capacity you use without long-term commitment or up front costs, however, you also don't have the benefit of discounts, you pay the full price. These instances run on a shared EC2 host but are isolated from other instances. On demand instances do not suffer interruption, and do not offer capacity reservation. You can change the instance type of an EC2 instance if it's stopped.</p>\n<p><strong>Reserved Instances</strong> provide a discounted hourly rate for EC2 instances, but it requires a long-term <strong>commitment of 1 or 3 years</strong>. You can choose to pay <strong>All upfront</strong>, <strong>Partial Upfront</strong> or <strong>No Upfront</strong> depending on your option you might get a better fee rate discount. There are two scopes of Reserved Instances:</p>\n<ul>\n<li><strong>Regional</strong>: Reservation applies to a region. It doesn't reserve capacity. But, the discount applies regardless of the AZ you deploy your instance and as regardless of the size of the instance, as long it using the reserved family.</li>\n<li><strong>Zonal</strong>: Reservation applies to an AZ. It reserves capacity. The discounts only apply if the reservation's AZ, instance type and size matches the EC2 instance type.</li>\n</ul>\n<p>In addition to the scope you also have to choose a offering class for the reservation instance. There's also two options:</p>\n<ul>\n<li><strong>Standard</strong>: Higher discount, don't allow exchange. Allows to buy and sell in Marketplace.</li>\n<li><strong>Convertible</strong>: Lower discount, allows exchange. Don't allow to buy and sell in Marketplace.</li>\n</ul>\n<p>RI allow you to modify the instance size(within same family and generation), the AZ and the scope. You can also modify a subset of a RI or merge two RIs. Convertible RI also allow you to exchange the RI to another RI with different configuration.</p>\n<p>You can also choose to launch <strong>Spot instances</strong>, this option takes advantage of unused EC2 capacity in the AWS Cloud. It works as an auction, you set a limit on how much you would pay for the instance hour, and as long the Spot instance fee is lower than the amount you specified you can use the EC2 instance. The fee is determined based on usage of the AWS Cloud. Because, this type of instance has interruption, applications running on spot instances should be able to tolerate interruptions. AWS gives you 2 minutes warning before interrupts the instance.</p>","frontmatter":{"title":"EC2 - Amazon Elastic Compute Cloud"},"isFile":true,"fileName":"elastic-compute-cloud"},{"fileAbsolutePath":"/home/runner/work/rroggia.github.io/rroggia.github.io/engineer-diary/AWS/compute/lambda.md","html":"<p><a href=\"https://docs.aws.amazon.com/lambda/index.html\">Documentation</a></p>\n<h2>Overview</h2>\n<p>It's one of the AWS compute services that enable you to run code without the need to provision or manage any servers. It's high-available, auto scalable, you don't pay for idle resources only for use, easy to use with little configurations.</p>\n<h2>Core Concepts</h2>\n<p>The <strong>Lambda function</strong> is the basic unit of this service, the Lambda Function contains all the data and configuration required to execute your function's code. When you create a Lambda function you need to provide the <strong>Function's</strong> <strong>Code</strong>, the <strong>Runtime</strong> which provides the programming language environment your function expects and the <strong>Handler</strong>, the function's entry point.</p>\n<p>When you are deploying your code there are two types of <strong>Deployment Packages</strong> you can choose:</p>\n<ul>\n<li><strong>Zip</strong>: A <code>.zip</code> file containing your code and all its dependencies required to run. Instead of sending the <code>.zip</code> file, you can store the file in S3 and specify the S3 Bucket with the file S3 Key.</li>\n<li><strong>Image</strong>: A Container Image following the OCI (Open Container Initiative) containing the OS, Runtime, the function's code and runtime. You provide the image through the Amazon Elastic Container Registry (ECR).</li>\n</ul>\n<p>Even though you can use Docker Images to do the deployment, it still need to comply to the AWS Lambda programming model in order to work. Its advantage is that it allows you to run runtime environment that are not supported by AWS.</p>\n<p>Now that you have a Lambda function, you can invoke it to execute your function. When a Lambda function is invoked, if no <strong>Execution Environment</strong> are free to be used, a new one is created. When the Lambda invocation requires a new Execution Environment we say it's a <strong>Cold Start</strong>. A Execution Environment only processes one invocation per time, but, after it finishing processing an invocation it can be reused and start to processing the next invocation. When the execution environment is reused we call it a <strong>Warm Start</strong>. Lambda supports concurrency by creating new Execution Environments. Because of Warm starts, it's possible to use storage or memory to speed up future invocations of an Execution Environment, however, the code must support Cold starts.</p>\n<p>The Execution Environment manages the <strong>Memory</strong>, <strong>Timeout</strong> and <strong>Ephemeral Storage</strong> specified in the Lambda function's configuration. You increase your Lambda's compute power by increasing its memory.</p>\n<p>During the Lambda Function execution the function assumes an <strong>Execution Role</strong>, an <strong>IAM Role</strong> that is specified during the Lambda Function creation. It specifies the permissions that the function has. Besides the IAM Role, you can also specify an <strong>IAM Resource Policies</strong> which enables you to add permissions to external Principals.</p>\n<p>You can use several tools to invoke your function like the Lambda console, a function URL endpoint, AWS SDK, the AWS CLI and more. In addition, the Lambda function can have <strong>Triggers</strong>, a resource configured that allow another AWS Services to invoke the function if certain event or condition occur.</p>\n<p>There are two types of Lambda function invocation Synchronous and Asynchronous.</p>\n<p><strong>Synchronous</strong> invocations you wait the lambda to process the event and respond. The API Gateway sends synchronous invocation.</p>\n<p>For <strong>Asynchronous</strong> invocations, the Lambda queues the events for processing and returns a response immediately. This type of invocation supports <strong>retries</strong>, <strong>Max Age of Event</strong>, a <strong>Dead Letter Queue</strong> (DLQ) and you can configure it to send response to <strong>Destinations</strong> (SQS queue, SNS topic, Lambda or EventBrige). You can have different destinations in case of failure or success.</p>\n<p>The DLQ is an alternative to the <strong>on-failure Destination</strong> their differences are that DLQ is tied to function's version specific configuration while the Destination is not, the destination also supports additional targets.</p>\n<p>S3 and SNS are examples of AWS Services that invoke asynchronously.</p>\n<p>There's a third way to invoke lambda functions using an <strong>Event Source Mapping</strong>. An Event source mapping is a Lambda managed resource that reads the data from an Event Source and invokes the Lambda function with the data. You can use it with services that do not invoke a Lambda function directly. For example, Amazon Kinesis streams or SQS. When using Event source mapping, by default it uses batch records together in a single payload. Similarly to the Asynchronous invocation it supports retrial of the whole batch, destinations and DLQ.</p>\n<p><strong>Log</strong></p>\n<p><strong>Alias</strong></p>\n<p><strong>Version</strong></p>\n<p><strong>Layer??</strong></p>\n<p><strong>Env var</strong></p>\n<p><strong>private networking</strong></p>\n<p><strong>concurrency</strong></p>\n<p><strong>provisioned</strong> </p>","frontmatter":{"title":"Lambda"},"isFile":true,"fileName":"lambda"}],"folders":[]}},
    "staticQueryHashes": ["1507822185","2095566405","2894216461","425755332"]}