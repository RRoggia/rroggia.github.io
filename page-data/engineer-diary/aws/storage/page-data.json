{
    "componentChunkName": "component---src-templates-folder-template-js",
    "path": "/engineer-diary/aws/storage",
    "result": {"pageContext":{"parentPath":"/engineer-diary/aws/storage","files":[{"fileAbsolutePath":"/home/runner/work/rroggia.github.io/rroggia.github.io/engineer-diary/AWS/storage/simple-storage-service.md","html":"<p><a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html\">Documentation</a></p>\n<h2>Overview</h2>\n<p>S3 is an fully managed service by AWS with regional resiliency. S3 is a type of Object storage, therefore, it stores objects in buckets with a flat structure, each object uploaded receives a key which can be used to retrieve or update the object later.</p>\n<p>S3 offers a several features like static website hosting, object versioning, bucket replication across regions and on same region, life cycle configuration rules to choose the most appropriate storage class and more.</p>\n<h2>Core Concepts</h2>\n<p>A <strong>bucket</strong> is a container for objects. By default, when you create a bucket, it's private and only the account root user has permissions to access it. You can add Identity or Resource policies to grant permission to access the bucket. However, only the Bucket policy, which is an resource policy, can grant access to different accounts and anonymous principal. S3 also supports ACLs which are a legacy way of granting permission that provides less flexibility, since it always applies to buckets and objects. </p>\n<p>When you create the bucket you need to choose a globally unique name. This name must be unique across all existing AWS accounts. In addition, you'll have to specify which region the bucket will reside, and unless explicit specified, the bucket data will remain on that region. The bucket is distributed across the several AZs of the chosen region.</p>\n<p>You upload <strong>Objects</strong> and its metadata to the bucket, when you upload the object it will receive a key that can be used to retrieve the object later. An object is an atomic unit, therefore, uploading objects with existing keys will overwrite the existing object, with exception of buckets with versioning enabled. Object size can range from 0 to 5TB. In addition, a bucket have virtually no limits of how many objects it can store.</p>\n<p>S3 has a flat structure, so it don't allows the creation of folders. However, you can use prefixes to logically group data, the AWS Management console will show the prefixes as folders, even though, in practice they aren't.</p>\n<h3>Storage Classes</h3>\n<p>S3 provides several Storage classes that support several types of data usage. You can consider S3 having two families S3 and S3 Glacier (cold storage).</p>\n<ul>\n<li><strong>S3 Standard</strong>: General purpose. Frequently accessed objects that contains important data and is not replaceable. This Storage classes will distribute the data in at least 3 AZs.</li>\n<li><strong>S3 Infrequent Access</strong>: Objects that have infrequent access, but are long lived, important and not replaceable. Storage cost is cheaper than S3 Standard, but, you pay a retrieval fee each time you need to access the object. This Storage classes will distribute the data in at least 3 AZs.</li>\n<li><strong>S3 One Zone Infrequent Access</strong>: Similar to S3 IA, however, it only distributes in 1 AZ. Therefore, should be used for non critical data with infrequent access that is easily replaceable.</li>\n<li><strong>S3 Glacier Instant Retrieval</strong>: Similar to S3 IA, however, it offers a cheaper cost, but higher retrieval fee. For data that needs to be accessed once per quarter.</li>\n<li>\n<p><strong>S3 Glacier Flexible Retrieval</strong>: For archive, objects cannot be made public and are do not provide instant access. When accessing you need to go through the retrieve process:</p>\n<ul>\n<li>Expedite: Moves data to IA temporary. Takes from 1 to 5 minutes.</li>\n<li>Standard: Moves data to IA temporary. Takes from 3 to 5 hours.</li>\n<li>Bulk: Moves data to IA temporary. Takes from 5 to 12 hours. </li>\n</ul>\n</li>\n<li>\n<p><strong>S3 Glacier Deep Archive</strong>: Similar to Flexible retrieval, but cheaper and longer retrieval processes.</p>\n<ul>\n<li>Standard: 12 hours.</li>\n<li>Bulk: Up to 48 hours.</li>\n</ul>\n</li>\n<li>\n<p><strong>S3 Intelligent-Tiering</strong>: For unknown or changing access patterns. Moves data across storage tiers.</p>\n<ul>\n<li>Standard, Infrequent Access, Glacier Archive Instant Retrieval</li>\n<li>(Optional) Archive access, Deep Archive</li>\n</ul>\n</li>\n</ul>\n<p>In addition, consider that:</p>\n<ul>\n<li>S3 IA: 30 days of minimun duration of charge and 128KB per object.</li>\n<li>S3 Glacier Instant Retrieval: 90 days of minimun duration of charge and 128KB per object.</li>\n<li>S3 Glacier Flexible Retrieval: 90 days of minimun duration of charge and 128KB per object.</li>\n<li>S3 Glacier Deep Archive: 180 days of minimun duration of charge and 40KB per object.</li>\n</ul>\n<h3>Versioning and MFA Delete</h3>\n<p>Because, Objects are an atomic unit, S3 provides <strong>versioning</strong> of objects. When the versioning is enabled, every new object uploaded to the bucket will receive a <strong>Version id</strong> property. Therefore, objects with the same key can have several versions and are differentiated by the version id. However, there's always only one current version of the object.</p>\n<p>When working with versioning enabled, when you delete an object without specifying its version, it creates a <strong>deletion marker</strong>, which acts as a soft delete and you can delete the deletion marker to restore the object version. When you delete a specific version of an object, then you apply a hard delete.</p>\n<p>A bucket has 3 versioning states.</p>\n<ul>\n<li>Unversioned: the default behavior</li>\n<li>Versioning enabled: Associates id to objects.</li>\n<li>Versioning suspended: Do not associates id to objects.</li>\n</ul>\n<p>Once you enabled the versioning, you can only suspend it, therefore, only the new objects will not have the id attribute fulfilled. But, the existing objects will keep the versions created, this is important because the  several version of this objects are considered in the pricing.</p>\n<p>Once you enable versioning, it's also possible to enable <strong>MFA Delete</strong> which adds a layer of security by requesting two authentication forms during the deletion of an object.</p>\n<h3>Static Website hosting</h3>\n<p>Static Website hosting is an S3 feature that can be used to host websites. You can use  this feature for scenarios where you want to offload static media (move media from a server to S3) or for out of band pages (maintenance or any content that cannot rely on the servers). This feature is very powerful and supports even full client side applications like Single Page Applications.</p>\n<p>When you enable the feature, you need to specify:</p>\n<ul>\n<li>index file: The initial html</li>\n<li>error file: An html for non existing routes</li>\n</ul>\n<p>You cannot choose the website endpoint, it's based on the bucket name. But, you can use Route 53 and CloudFront to create custom urls.</p>\n<p>Static website hosting adds to the pricing a fee for each 1000 requests.</p>\n<h3>Encryption</h3>\n<p>S3 Supports different types of data encryption at rest that are categorized in two groups:</p>\n<ul>\n<li>\n<p><strong>Server Side Encryption (SSE)</strong>: Data moves from client to AWS without encryption (only SSL). Encrypts data in the server.</p>\n<ul>\n<li><strong>Customer Provided Keys (SSE-C)</strong></li>\n<li>Customer manages the keys in the client side</li>\n<li>AWS manages the encryption/decryption in server side</li>\n<li><strong>S3-Manages Keys (SSE-S3)</strong></li>\n<li>AWS manages keys and the encryption/decryption in server side</li>\n<li>Uses AES256 encryption algorithm</li>\n<li>S3 creates Root Key to encrypt other keys</li>\n<li>Each object will create a key for the object encryption</li>\n<li>After encryption the key is encrypted by the root key and store with the object.</li>\n<li>The key is discarded.</li>\n<li>Doesn't support role separation </li>\n<li><strong>KMS (SSE-KMS)</strong></li>\n<li>AWS manages keys and the encryption/decryption in server side</li>\n<li>KMS provides a plain text key and a encrypted key to S3</li>\n<li>DEK are used to encrypt objects, and are stored with it</li>\n<li>Supports rotation and role separation</li>\n</ul>\n</li>\n<li>\n<p><strong>Client Side Encryption (CSE)</strong>: Data already moves to AWS encrypted</p>\n<ul>\n<li>The customer manages the keys in the client side</li>\n<li>The customer encrypts the objects in the client side</li>\n<li>The customer decrypts the objects in the client side</li>\n</ul>\n</li>\n</ul>\n<h3>Lifecycle configuration</h3>\n<h3>Replication</h3>\n<p>S3 are regional services, but the replication feature offers the possibility to replicate a Bucket to other regions or to the same region in the same or different accounts. The replication is not real-time, AWS tries to deliver in a 15 minutes range but doesn't provide guarantee. You can configure it to replicate the all objects or create a filter based on tags, prefixes or both and even change the storage class of the destination bucket.</p>\n<p>There are two types of replication:</p>\n<ul>\n<li>Cross Region Replication (CRR)</li>\n<li>Same Region Replication (SRR)</li>\n</ul>\n<p>Once the replication is activated it doesn't replicates objects retroactive, only new objects. It also requires versioning to be enabled in both source and destination buckets.</p>\n<p>The replication works as a one way replication, changes in the destination bucket to not reflect in the source bucket.</p>\n<h3>Pre signed URLs</h3>\n<h3>Object lock</h3>\n<h3>Select</h3>\n<p>It can be used to return parts of an object instead of the whole object. S3 Select uses SQL like statements to pre-filter data in server side and send only the filtered data to the client. Can be used with several formats file like csv, json or parquet.</p>\n<h3>Access Logs</h3>\n<h3>S3 Events</h3>\n<h3></h3>","frontmatter":{"title":"S3 - Simple Storage Service"},"isFile":true,"fileName":"simple-storage-service"}],"folders":[]}},
    "staticQueryHashes": ["1507822185","2095566405","2894216461","425755332"]}