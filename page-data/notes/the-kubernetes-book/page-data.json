{"componentChunkName":"component---src-templates-note-template-js","path":"/notes/the-kubernetes-book","result":{"data":{"markdownRemark":{"frontmatter":{"title":"The Kubernetes Book","date":"2022-07-06","published":null,"tags":null},"tableOfContents":"<ul>\n<li>\n<p><a href=\"#2-kubernetes-principles-of-operation\">2 Kubernetes principles of operation</a></p>\n<ul>\n<li><a href=\"#summary\">Summary</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#4-working-with-pods\">4 Working with Pods</a></p>\n<ul>\n<li><a href=\"#my-summary\">My Summary</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#5-kubernetes-deployment\">5 Kubernetes Deployment</a></p>\n<ul>\n<li><a href=\"#my-summary-1\">My Summary</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#6-kubernetes-services\">6 Kubernetes Services</a></p>\n<ul>\n<li><a href=\"#my-summary-2\">My Summary</a></li>\n</ul>\n</li>\n</ul>","html":"<h1>2 Kubernetes principles of operation</h1>\n<blockquote>\n<p>At the highest level, Kubernetes is two things:</p>\n<ul>\n<li>A cluster for running applications</li>\n<li>An orchestrator of cloud-native microservices apps</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>For production environments, multi-master high availability (HA) is a must have.</p>\n</blockquote>\n<blockquote>\n<p>Generally speaking, running 3 or 5 replicated masters in an HA (high availability) configuration is recommended.</p>\n</blockquote>\n<blockquote>\n<p>It's also considered a good practice not to run user applications on masters. This allows masters to concentrate entirely on managing the cluster.</p>\n</blockquote>\n<blockquote>\n<p>For an application to run on a Kubernetes cluster it needs to tick a few boxes. These include:</p>\n<ol>\n<li>Packaged as a container</li>\n<li>Wrapped in a Pod</li>\n<li>Deployed via a declarative manifest file</li>\n</ol>\n</blockquote>\n<blockquote>\n<p>The declarative model and the concept of desired state are at the very heart of Kubernetes.</p>\n</blockquote>\n<blockquote>\n<p>containers must always run inside of Pods.</p>\n</blockquote>\n<blockquote>\n<p>The simplest model is to run a single container per POD. However, there are advanced use-cases that run multiple containers inside a single Pod.</p>\n</blockquote>\n<blockquote>\n<p>a Pod is a ring fenced environment to run containers. The pod itself doesn't actually run anything, it's just a sandbox for hosting containers.</p>\n</blockquote>\n<blockquote>\n<p>If you need to scale your app, you add or remove Pods.</p>\n</blockquote>\n<blockquote>\n<p>Services use labels and a label selector to know which set of pods to load balance traffic to. The service has a label selector that is a list of all the labels a Pod must posses in order for it to receive traffic from the Service.</p>\n</blockquote>\n<h2>Summary</h2>\n<p>K8 cluster is a bunch of nodes and a control plane. The control plane exposes an HTTP RESTful API, it assign work to nodes through the scheduler and records states in a persistent store. Nodes are responsible for running the applications.</p>\n<p><strong>Masters:</strong> Schedule decisions, perform monitoring, implement changes, respond to events, and more.</p>\n<ul>\n<li>\n<p>API Server: The grand Central Station of k8. </p>\n<ul>\n<li>All communication goes through here.</li>\n<li>Exposes the RESTful API</li>\n</ul>\n</li>\n<li>\n<p>Cluster Store: The heart of K8.</p>\n<ul>\n<li>The only stateful part of the control plane.</li>\n<li>Cluster store based on etcd.</li>\n<li>3-5 replicas of etcd for HA.</li>\n</ul>\n</li>\n<li>\n<p>Controller manager: Controller of Controllers.</p>\n<ul>\n<li>Applies control loops to ensure desired and current state are the same. Reconcile if they arent.</li>\n<li>Each control loop is very specialized.</li>\n</ul>\n</li>\n<li>\n<p>Scheduler: Watches for new work and assign it to workers.</p>\n<ul>\n<li>Applies Filter and ranking logic to the nodes</li>\n</ul>\n</li>\n<li>Cloud Controller manager: Integrates with cloud technologies</li>\n</ul>\n<p><strong>Nodes:</strong> Where applications runs.</p>\n<ol>\n<li>Watch the API Server for new work assignment</li>\n<li>Execute new work assignments</li>\n<li>Report back to the control plane</li>\n<li>\n<p>kubelet: Runs on every node in the cluster.</p>\n<ul>\n<li>Watches the API Server</li>\n</ul>\n</li>\n<li>\n<p>container runtime: Container related tasks</p>\n<ul>\n<li>Pull images, start and stop containers and so on ...</li>\n<li>Container Runtime Interface</li>\n<li>containerd is one of the popular options. It's the docker container runtime, which was donated by docker to cncf.</li>\n</ul>\n</li>\n<li>kub-proxy: Responsible for local networking.</li>\n</ol>\n<p>K8 clusters have an internal DNS. The DNS service has a static IP address that is hard-coded into every Pod on the cluster.</p>\n<p><strong>Pods</strong>: Atomic unit of K8.</p>\n<p><strong>Deployments:</strong> Higher level K8 object that wraps around a Pod and adds functionality.</p>\n<p><strong>Services</strong>: Provide reliable networking for a set of Pods.</p>\n<ul>\n<li>Consists of a stable DNS name , IP address, and port. </li>\n<li>Load balancer for pods</li>\n</ul>\n<h1>4 Working with Pods</h1>\n<blockquote>\n<p>The atomic unit of scheduling in the virtualization world is the Virtual Machine. This means <strong>deploying applications</strong> in the virtualization world means scheduling them on VMs.</p>\n</blockquote>\n<blockquote>\n<p>In the Docker world, the atomic unit is the container. This means <strong>deploying applications</strong> on Docker means deploying them inside of containers.</p>\n</blockquote>\n<blockquote>\n<p>In the Kubernetes world, the atomic unit is the Pod. Ergo, <strong>deploying applications</strong> on kubernetes means stamping them out in Pods.</p>\n</blockquote>\n<blockquote>\n<p>(About Pod) they're bigger than a container, but a lot smaller than a VM.</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/images/concept.png\" alt=\"new concept\"> Pod is a shared execution environment for one or more containers.</p>\n</blockquote>\n<blockquote>\n<p>By running the web server container and the file-sync container in the same Pod, we ensure they will always be deployed to the same code.</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/images/concept.png\" alt=\"new concept\"> <em>Shared execution environment</em> means that the Pod has a set of resources (IP, ports, hostname, memory, volumes, ...) that are shared by every container that is part of the Pod.</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/images/concept.png\" alt=\"new concept\"> a Pod is actually a special type of container called a pause container.</p>\n</blockquote>\n<blockquote>\n<p>the Pod (pause container) is just a collection of system resources that containers running inside of it will inherit and share. These system resources are kernel namespaces and include:</p>\n<ul>\n<li>Network namespace: IP address, port range, routing table, ...</li>\n<li>UTS namespace: Hostname</li>\n<li>IPC namespace: Unix domain sockets</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>This networking model makes <em>inter-Pod</em> communication really simple. Every Pod in the cluster has its own IP addresses that's fully routable on the Pod network.</p>\n</blockquote>\n<blockquote>\n<p> Because every Pod gets its own routable IP, every Pod on the Pod network can talk directly to every other Pod without messing around with things like nasty port mappings.</p>\n</blockquote>\n<blockquote>\n<p><img src=\"/images/concept.png\" alt=\"new concept\"> Control Groups (cgroups) prevent individual containers from consuming all of the available CPU, RAM and IOPS on a node.</p>\n</blockquote>\n<blockquote>\n<p>We could say that cgroups actively police resource usage.</p>\n</blockquote>\n<blockquote>\n<p>Individual containers have their own cgroup limits.</p>\n</blockquote>\n<blockquote>\n<p>Deploying a Pod is an atomic operation.</p>\n</blockquote>\n<blockquote>\n<p>Pods that are deployed via Pod manifest files are singletons - they are not replicated and have no self-healing capabilities. For this reason, we almost always deploy Pods via higher-level objects like Deployments and DaemonSets, as these can reschedule Pods when they fail.</p>\n</blockquote>\n<blockquote>\n<p>namespaces allow us to logically divide clusters for management purposes.</p>\n</blockquote>\n<h2>My Summary</h2>\n<p>Deploying applications:</p>\n<ul>\n<li>VM -> scheduling a deploy in a VM</li>\n<li>Docker -> deploying a container</li>\n<li>Kubernetes -> deploying a Pod</li>\n</ul>\n<p><strong>What's a POD?</strong></p>\n<p>It's a shared execution environment for containers. It defines the system resources like IP, port ranges, host name, ... the containers will inherit. </p>\n<p>A pod is bigger than a container but smaller than a VM. Within a POD you can run multiple containers, and the will share the POD resources. </p>\n<p>In the docker language, a POD is a pause container, a collection of system resources that containers within it will inherit. That's why the shared execution environment.</p>\n<p>Network:</p>\n<ul>\n<li>intra POD: you can use localhost and the port. Useful for multi containers.</li>\n<li>inter POD: PODs can easily talk with other PODs due the POD network. </li>\n</ul>\n<p>To deploy a Pod, send the POST manifest to the API Server. The control plane stores the intent. And the scheduler deploys to a healthy node with enough resources.</p>\n<p>A best practice is to handle PODs as stateles due their ephemeral existence. Avoid storing states or relying on PODs IPs.</p>\n<p>Pods don't self-heal, they don't scale, and they don't allow for easy updates or rollbacks.</p>\n<p><strong>Pod lifecycle</strong></p>\n<p>Pending -> while download image and starts all the containers.</p>\n<p>Running -> Once everything is running.</p>\n<p>Succeeded -> All tasks were completed.</p>\n<p>Failed -> When a POD cannot start or if they break when running.</p>\n<p>Threat Pods as mortal, or cattle (pets vs cattle analogy). Once they die, replace with a new one instead of bringing the old one back.</p>\n<p><strong>What's a CGroup?</strong></p>\n<p>A control group avoid containers to use all resources from a node.</p>\n<p>The CGroup is applyed at container level. Having the CGroup applyed at container level, enables in a multi container POD to stablish resource boundaries (cgroups) for each container.</p>\n<h1>5 Kubernetes Deployment</h1>\n<blockquote>\n<p>It's important to know that a single Deployment can only manage a single type of Pod.</p>\n</blockquote>\n<blockquote>\n<p>Deployment can manage multiples replicas of the same Pod.</p>\n</blockquote>\n<blockquote>\n<p>behind-the-scene, Deployments leverage another object called a ReplicaSet.</p>\n</blockquote>\n<blockquote>\n<p>it's best practice that we don't directly manage ReplicaSets</p>\n</blockquote>\n<blockquote>\n<p>Deployments use ReplicaSets to provide self-healing and scalability</p>\n</blockquote>\n<blockquote>\n<p><em>Desired state</em> is what you want. <em>Current state</em> is what you have. If the two match, everybody's happy.</p>\n</blockquote>\n<blockquote>\n<p>A <em>Declarative model</em> is a way of telling Kubernetes what our desired state is, without having to get into the detail of <em>how</em> to implement it.</p>\n</blockquote>\n<blockquote>\n<p>Kubernetes supports both models (Declarative and Imperative), but strongly prefers the declarative model.</p>\n</blockquote>\n<blockquote>\n<p>Kubernetes is constantly making sure <em>current state</em> matches <em>desired state</em>.</p>\n</blockquote>\n<h2>My Summary</h2>\n<p><strong>What's a Deployment?</strong></p>\n<p>A Deployment is a kubernetes object that adds capabilities to the Pod.</p>\n<p>Capabilities:</p>\n<ul>\n<li>Zero downtime</li>\n<li>Liveness Checks</li>\n<li>Readiness Checks</li>\n<li>Rolling updates (Through Deployment)</li>\n<li>Rollbacks (Through Deployment)</li>\n<li>Self-healing (Through ReplicaSet)</li>\n<li>Scalability (Through ReplicaSet)</li>\n</ul>\n<p>A Deployment wraps a ReplicaSet, which wraps a Pod. It's a best practice to not manage ReplicaSet, and to use Deployments.</p>\n<p><strong>What are the k8 states?</strong></p>\n<p>K8 uses 2 states the desired state (what you want) and the current state (what you got).</p>\n<p><strong>What's the reconciliation loop?</strong></p>\n<p>The reconciliation loops validate whether desire and current state match and if they don't triggers an action to make they match.</p>\n<p>The reconciliation loops is used for both self-healing and scalability.</p>\n<p><strong>How Deployment deal with updates?</strong></p>\n<p>Deployment deal with updates by adding another ReplicaSet with the new configuration. So, while the new ReplicaSet spins up all the Pods both ReplicaSet will be active. As soon, the ReplicaSet with the updated information is ready, the old ReplicaSet starts decreasing it's Pods (But the ReplicaSet is not deleted). Therefore, updates have a zero downtime.</p>\n<p><strong>How Deployment deal with Rollbacks?</strong></p>\n<p>Because the Deployment has the ReplicaSet with previous configuration, whenever you want to rollback your application you can spin up an old ReplicaSet and wind down the current ReplicaSet.</p>\n<h1>6 Kubernetes Services</h1>\n<blockquote>\n<p>Kubernetes Services give us the networking we <strong>can</strong> rely on.</p>\n</blockquote>\n<blockquote>\n<p>a Kubernetes <strong>Service</strong> is an object in the API that we define in a manifest and POST to the API server.</p>\n</blockquote>\n<blockquote>\n<p>every Service gets its own stable IP address, its own stable DNS name, and its own stable port.</p>\n</blockquote>\n<blockquote>\n<p>Services use labels to dynamically select the Pods in the cluster they will sen traffic to.</p>\n</blockquote>\n<h2>My Summary</h2>"}},"pageContext":{"title":"The Kubernetes Book"}},"staticQueryHashes":["1507822185","2095566405","2894216461","425755332"]}